{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\"> Next Man Up: NBA, WNBA, G-League, NCAA Player Clustering Similarity </h1>\n",
    "\n",
    "Last Modified: *7/28/2024*\n",
    "\n",
    "### **Goal**: Implement clustering model to group NBA, WNBA, and G League players based on traditional and advanced box score statistics to:\n",
    "\n",
    "1. Identify potential role player replacements\n",
    "\n",
    "2. Scout emerging talent\n",
    "\n",
    "3. Provide contingency planning for injuries and trades\n",
    "\n",
    "Final result will include clustering plots for each league.\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "import collections\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from datetime import datetime\n",
    "\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Arc\n",
    "\n",
    "from nba_api.stats.endpoints import commonplayerinfo, leaguegamefinder, boxscoreadvancedv2, BoxScoreDefensiveV2, PlayerGameLog\n",
    "from nba_api.stats.static import players, teams\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None  # Disabling pandas SetWithCopyWarnings\n",
    "os.add_dll_directory(r\"C:\\Program Files\\GTK3-Runtime Win64\\bin\")\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from py_ball import synergy, image\n",
    "\n",
    "# Adjust the amount of jitter as needed\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "HEADERS = {'Connection': 'keep-alive',\n",
    "           'Host': 'stats.nba.com',\n",
    "           'Origin': 'http://stats.nba.com',\n",
    "           'Upgrade-Insecure-Requests': '1',\n",
    "           'Referer': 'stats.nba.com',\n",
    "           'x-nba-stats-origin': 'stats',\n",
    "           'x-nba-stats-token': 'true',\n",
    "           'Accept-Language': 'en-US,en;q=0.9',\n",
    "           \"X-NewRelic-ID\": \"VQECWF5UChAHUlNTBwgBVw==\",\n",
    "           'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6)' +\\\n",
    "                         ' AppleWebKit/537.36 (KHTML, like Gecko)' + \\\n",
    "                         ' Chrome/81.0.4044.129 Safari/537.36'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-defined Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_closest_players(df, player_name, k):\n",
    "    ### Returns the k nearest neighbors most similar to player_name\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def generate_random_color():\n",
    "    return f'#{random.randint(0, 0xFFFFFF):06x}'\n",
    "\n",
    "\n",
    "def return_player_bio(player_id):\n",
    "    # returns player position, height, and weight as a list using nba_api library\n",
    "\n",
    "    player_info = commonplayerinfo.CommonPlayerInfo(player_id=player_id)\n",
    "    player_info_dict = player_info.get_normalized_dict()\n",
    "\n",
    "    # Extract relevant data\n",
    "    position = player_info_dict['CommonPlayerInfo'][0]['POSITION']\n",
    "    height = player_info_dict['CommonPlayerInfo'][0]['HEIGHT']\n",
    "    weight = player_info_dict['CommonPlayerInfo'][0]['WEIGHT']\n",
    "\n",
    "    return [position, height, weight]\n",
    "\n",
    "\n",
    "def encode_image(image):\n",
    "    # converts img file from PIL library to PNG, meant to retain quality of image when plotting\n",
    "    \n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format='PNG')\n",
    "    encoded_image = base64.b64encode(buffer.getvalue()).decode()\n",
    "    return f'data:image/png;base64,{encoded_image}'\n",
    "\n",
    "\n",
    "\n",
    "def plotly_clusters(df, league, season_start, season_end):\n",
    "    \n",
    "    x_min = df['x'].min()\n",
    "    x_max = df['x'].max()\n",
    "    y_min = df['y'].min()\n",
    "    y_max = df['y'].max()\n",
    "\n",
    "    df['hover_text'] = df.apply(lambda row: f\"Name: {row['PLAYER_NAME']}<br>PTS: {row['PTS']:.1f}<br>AST: {row['AST']:.1f}<br>REB: {row['REB']:.1f}\", axis=1)\n",
    "\n",
    "    # Create scatter plot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add scatter trace for hover text\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['x'],\n",
    "        y=df['y'],\n",
    "        mode='markers',\n",
    "        marker=dict(size=10, color='rgba(255, 255, 255, 0)'),\n",
    "        text=df['hover_text'],\n",
    "        hoverinfo='text',\n",
    "        showlegend=False\n",
    "    ))\n",
    "    \n",
    "    if league == 'NBA' or league == 'WNBA':\n",
    "        # Add images as scatter points\n",
    "        for i, row in df.iterrows():\n",
    "            fig.add_layout_image(\n",
    "                dict(\n",
    "                    source=row['IMAGE_ENCODED'],\n",
    "                    x=row['x'],\n",
    "                    y=row['y'],\n",
    "                    xref=\"x\",\n",
    "                    yref=\"y\",\n",
    "                    sizex=10,  # Adjust size as needed\n",
    "                    sizey=10,\n",
    "                    xanchor=\"center\",\n",
    "                    yanchor=\"middle\"\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        # Initialize the color map with random colors\n",
    "        unique_clusters = df['cluster'].unique()\n",
    "        color_map = {cluster: generate_random_color() for cluster in unique_clusters}\n",
    "\n",
    "        # Map the clusters to colors\n",
    "        colors = df['cluster'].map(color_map)\n",
    "\n",
    "        # Add scatter trace\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df['x'], \n",
    "            y=df['y'], \n",
    "            mode='markers',\n",
    "            marker=dict(color=colors),\n",
    "            showlegend=False\n",
    "        ))\n",
    "\n",
    "\n",
    "\n",
    "    # Update layout for better display\n",
    "    fig.update_layout(\n",
    "        autosize=True,\n",
    "        xaxis=dict(range=[x_min, x_max], visible = False),  # Adjust range to include all points\n",
    "        yaxis=dict(range=[y_min, y_max], visible = False),  # Adjust range to include all points\n",
    "        hovermode='closest',\n",
    "        title=dict(\n",
    "            text=(f\"<b>{league} Player Clustering</b><br><sup>Regular season & Playoff data spanning from {season_start} to {season_end}</sup>\"),\n",
    "            x=0.12,  # Move title slightly to the right\n",
    "            xanchor='left'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    \n",
    "    if league == 'WNBA':\n",
    "        with open(\"C:/Users/rsandan/Downloads/WNBA.png\", \"rb\") as image_file:\n",
    "            img_str = base64.b64encode(image_file.read()).decode()\n",
    "        source = f\"data:image/png;base64,{img_str}\"\n",
    "        x=-.03\n",
    "        y=1.35\n",
    "    elif league == 'NBA':\n",
    "        source = \"https://raw.githubusercontent.com/TGOlson/nba-logos/main/data/img/NBA.png\"\n",
    "        x=-.01\n",
    "        y=1.35\n",
    "    else:\n",
    "        with open(\"C:/Users/rsandan/Downloads/gleague.png\", \"rb\") as image_file:\n",
    "            img_str = base64.b64encode(image_file.read()).decode()\n",
    "        source = f\"data:image/png;base64,{img_str}\"\n",
    "        x=0\n",
    "        y=1.35\n",
    "\n",
    "    # Add logo image\n",
    "    fig.add_layout_image(\n",
    "        dict(\n",
    "            source=source,\n",
    "            xref=\"paper\", yref=\"paper\",\n",
    "            x=x, y=y,\n",
    "            sizex=0.35, sizey=0.35,\n",
    "            xanchor=\"left\", yanchor=\"top\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def season_string(start, end):\n",
    "    # Split the input strings to get the start and end years\n",
    "    start_year = int(start.split('-')[0])\n",
    "    end_year = int(end.split('-')[0])\n",
    "    \n",
    "    # Create a list to store the season strings\n",
    "    seasons = []\n",
    "    \n",
    "    # Loop through the range of years and generate the season strings\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        next_year = str(year + 1)[-2:]  # Get the last two digits of the next year\n",
    "        season = f\"{year}-{next_year}\"\n",
    "        seasons.append(season)\n",
    "    \n",
    "    return seasons\n",
    "\n",
    "\n",
    "def fetch_season_data(league_id, season_start, season_end, season_type):\n",
    "    all_data = []\n",
    "\n",
    "    # WNBA seasons are simply 2000, 2001, etc.\n",
    "    if league_id == '10':\n",
    "        seasons = range(season_start, season_end)\n",
    "    else: \n",
    "        seasons = season_string(season_start, season_end)\n",
    "\n",
    "        \n",
    "    for season in seasons:\n",
    "        nba_gamefinder = leaguegamefinder.LeagueGameFinder(\n",
    "            league_id_nullable=league_id,\n",
    "            season_nullable=season,\n",
    "            season_type_nullable=season_type,\n",
    "            player_or_team_abbreviation='P'\n",
    "        )\n",
    "        games = nba_gamefinder.get_data_frames()[0]\n",
    "        all_data.append(games)\n",
    "        \n",
    "        print(f'Finished scraping data for the {season} season ({season_type}). Amount of rows =', len(games))\n",
    "        \n",
    "        # Optional: Add a delay to avoid overloading the server\n",
    "        lag = np.random.uniform(low=2, high=5)\n",
    "        print(f'...waiting {round(lag, 1)} seconds')\n",
    "        time.sleep(lag)\n",
    "    \n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "def apply_tsne(df, num_of_clusters, numeric_columns, gleague = 'no'):\n",
    "    X = np.array(df[numeric_columns])\n",
    "    kmeans = KMeans(n_clusters = num_of_clusters, random_state = 42).fit(X)\n",
    "    labels = kmeans.labels_\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "    # set verbose to 2 to see output messages from T-SNE\n",
    "    data_dim = TSNE(n_components=2, perplexity=5, verbose=0, method='barnes_hut').fit_transform(X)\n",
    "    cluster_centers_dim = TSNE(n_components=2, perplexity=1, verbose=0, method='barnes_hut').fit_transform(cluster_centers)\n",
    "\n",
    "    data_dim_x = [i[0] for i in data_dim]\n",
    "    data_dim_y = [i[1] for i in data_dim]\n",
    "\n",
    "    cluster_center_x = [i[0] for i in cluster_centers_dim]\n",
    "    cluster_center_y = [i[1] for i in cluster_centers_dim]\n",
    "\n",
    "    cluster_center_labels = [0, 1, 2, 3, 4]\n",
    "\n",
    "    data_point_table = pd.DataFrame({'x': data_dim_x, 'y': data_dim_y, 'cluster': labels})\n",
    "    data_point_table['cluster_center_x'] = data_point_table['cluster'].map(dict(zip(cluster_center_labels, cluster_center_x)))\n",
    "    data_point_table['cluster_center_y'] = data_point_table['cluster'].map(dict(zip(cluster_center_labels, cluster_center_y)))\n",
    "    data_point_table['PLAYER_NAME'] = df['PLAYER_NAME'].values\n",
    "    data_point_table['PTS'] = df['PTS'].values\n",
    "    data_point_table['AST'] = df['AST'].values\n",
    "    data_point_table['REB'] = df['REB'].values\n",
    "\n",
    "\n",
    "    if gleague == 'no':\n",
    "        # Add encoded images and player names to the dataframe\n",
    "        data_point_table['IMAGE'] = df['IMAGE'].values\n",
    "        data_point_table['IMAGE_ENCODED'] = data_point_table['IMAGE'].apply(encode_image)\n",
    "    \n",
    "\n",
    "    return data_point_table\n",
    "\n",
    "def grab_player_headshots(df, league):\n",
    "    player_data = []\n",
    "\n",
    "    df_unique = df[['PLAYER_NAME', 'PLAYER_ID']].drop_duplicates()\n",
    "\n",
    "    for index, row in df_unique.iterrows():\n",
    "        player_id = row['PLAYER_ID']\n",
    "        player_name = row['PLAYER_NAME']\n",
    "        try:\n",
    "            image_url = image.Headshot(league=league, player_id=player_id).image\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {player_name} (ID: {player_id}): {e}\")\n",
    "            # Add default image on error (Javale McGee)\n",
    "            image_url = \"url_to_default_image\"\n",
    "\n",
    "        player_data.append({\n",
    "            'PLAYER_NAME': player_name,\n",
    "            'PLAYER_ID': player_id,\n",
    "            'IMAGE': image_url\n",
    "        })\n",
    "\n",
    "\n",
    "    return pd.DataFrame(player_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# League IDs\n",
    "nba_league_id = '00'\n",
    "g_league_id = '20'\n",
    "wnba_league_id = '10'\n",
    "\n",
    "# Season Parameters\n",
    "season_start = '2022-23'\n",
    "season_end = '2023-24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fetch regular season and playoffs data (NBA)\n",
    "nba_rs_data = fetch_season_data(league_id=nba_league_id, season_start=season_start, season_end=season_end, season_type='Regular Season')\n",
    "nba_p_data = fetch_season_data(league_id=nba_league_id, season_start=season_start, season_end=season_end, season_type='Playoffs')\n",
    "\n",
    "# Fetch regular season and playoffs data (G League)\n",
    "gleague_rs_data = fetch_season_data(league_id=g_league_id, season_start=season_start, season_end=season_end, season_type='Regular Season')\n",
    "gleague_p_data = fetch_season_data(league_id=g_league_id, season_start=season_start, season_end=season_end, season_type='Playoffs')\n",
    "\n",
    "# Fetch regular season and playoffs data (WNBA)\n",
    "wnba_rs_data = fetch_season_data(league_id=wnba_league_id, season_start=2015, season_end=2024, season_type='Regular Season')\n",
    "wnba_p_data = fetch_season_data(league_id=wnba_league_id, season_start=2015, season_end=2024, season_type='Playoffs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate every df into one main df\n",
    "master = pd.concat([nba_rs_data, nba_p_data, \n",
    "                    gleague_rs_data, gleague_p_data, \n",
    "                    wnba_rs_data, wnba_p_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My next step is to create two new columns that differentiate league data `LEAGUE` (nba, g league, wnba) and `SEASON_TYPE` (regular season & playoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['SEASON_ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 indicates regular season\n",
    "- 4 indicates playoff data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_teams = master[['TEAM_ID', 'TEAM_NAME']].drop_duplicates()\n",
    "\n",
    "# Set pandas option to display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Display the unique teams\n",
    "print(unique_teams.sort_values(by='TEAM_ID'))\n",
    "\n",
    "# Optionally, reset the display option to default after displaying\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at `Team ID`:\n",
    "- NBA starts with 16106...\n",
    "- WNBA starts with 16116...\n",
    "- G LEAGUE with 16127..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the appropriate changes\n",
    "\n",
    "# Add new column to indicate season_type\n",
    "master['SEASON_TYPE'] = ['Regular Season' if str(row)[0] == '2' else 'Playoffs' for row in master['SEASON_ID']]\n",
    "\n",
    "# Add new column to indicate league\n",
    "league_types = []\n",
    "for row in master['TEAM_ID']:\n",
    "    if str(row)[:5] == '16106':\n",
    "        league_types.append('NBA')\n",
    "    elif str(row)[:5] == '16116':\n",
    "        league_types.append('WNBA')\n",
    "    else:\n",
    "        league_types.append('G LEAGUE')\n",
    "\n",
    "master['LEAGUE'] = league_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique players in dataset\", len(master['PLAYER_ID'].unique()))\n",
    "print(\"\\nSplit by league:\\n\")\n",
    "\n",
    "for league in master['LEAGUE'].unique():\n",
    "    temp = master[master['LEAGUE'] == league]\n",
    "    print(\"Number of\", league, \"players: \", len(temp['PLAYER_ID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify which features have missing values\n",
    "master.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the NA WL are coming from G-League data\n",
    "master[master['WL'].isna()]['LEAGUE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the NA player names are coming from G-League data\n",
    "master[master['PLAYER_NAME'].isna()]['LEAGUE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pre-processing Questions:\n",
    "- What are potential reasons why `PLAYER_NAME` is missing? (but they have `PLAYER_ID` for those missing players)\n",
    "- Missing data on who won `WL`? Did it go to overtime?\n",
    "- bunch of NA values for percentage columns `FT_PCT`, `FG_PCT`, `FG3_PCT` to indicate that a player did not attempt a field goal, therefore they did not make a field goal either. So 0/0 = NA\n",
    "- bunch of NA values for `PLUS_MINUS`\n",
    "- `REB` shouldn't have any NA values since `REB` = `OREB` + `DREB`. So 0 = 0 + 0 should work out.\n",
    "\n",
    "\n",
    "To do:\n",
    "- Exclude rows where `PLAYER_NAME` is NA\n",
    "- Exclude rows where `WL` is NA\n",
    "- Drop Percentage columns since it's redundant (we can compute percentage already using `FGA` and `FGM`)\n",
    "- Ensure `REB` = `DREB` + `OREB`\n",
    "- DROP `PLUS_MINUS`\n",
    "- Change stats like `PTS` to float data type\n",
    "- [TENTATIVE] Add advanced metrics such as:\n",
    "  - `TS_PERC`: True shooting percentage\n",
    "  - `PPP`: Points Per Possession\n",
    "  - `PER`: Player Efficiency Rating\n",
    "- Add player headshots to dataframe using `grab_player_headshots` function for visual aid in clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why drop `PLUS_MINUS`? Take this excerpt from [blazersedge.com, written by Dave Deckard,](https://www.blazersedge.com/2024/3/31/24117295/nba-plus-minus-portland-trail-blazers-scoot-henderson-record) explaining the problem with plus minus: \"The nice thing about plus/minus is that it indicates, at least partially, how a player’s performance might be affecting his team. If you notice a guy scoring 20 per game, but his plus/minus runs consistently negative, you might begin to suspect that his scoring isn’t as valuable as it seems on the surface.\n",
    "\n",
    "On the other hand, maybe not. The problematic part of plus/minus is the statistical “noise” accompanying it. Team performance provides the baseline for the stat, but the stat is applied to a single player. Those do not match up.\n",
    "\n",
    "If you send Damian Lillard onto the floor of an NBA game with four preschoolers, he’s going to have a horrible plus/minus even though he’s a fantastic player. His individual play-making and/or skills won’t be able to overcome the gravity of the team’s demise. Nor would the loss (and the terrible plus/minus stat on his boxscore line) be his fault.\" \n",
    "\n",
    "Since we're only focusing on individual players and not groups (i.e. starters and bench players), this stat won't provide valuable insight to an individual player's performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TENTATIVE] Why add `TS_PERC`, `PPP`, `PER`? \n",
    "- I wanted to add true shooting percentage because unlike effective field goal percentage, it takes freethrows into account. \n",
    "- I wanted to add Points Per Possession because it accounts for the number of possessions used, giving a clearer picture of scoring effectiveness compared to raw points alone.\n",
    "- Adding Player Efficiency Rating because it's a good overall metric taking positive and negative stats into account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the appropriate changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude player data where the value of WL is Not Available\n",
    "master = master[master['WL'].notna()]\n",
    "\n",
    "# Exclude rows of player data where their name isn't available. I noticed that it's all g_league too.\n",
    "master = master[master['PLAYER_NAME'].notna()]\n",
    "\n",
    "# Exclude row where FGA is NA\n",
    "master = master[master['FGA'].notna()]\n",
    "\n",
    "# Drop percentage and plus minus columns\n",
    "master = master.drop(columns=['FG_PCT', 'FG3_PCT', 'FT_PCT', 'PLUS_MINUS'])\n",
    "\n",
    "# Ensure REB column is sum of offensive and defensive rebounds\n",
    "master['REB'] = master['DREB'] + master['OREB']\n",
    "\n",
    "# Map 'W' to 1 (win) and 'L' to 0 (loss)\n",
    "result_list = [1 if i == 'W' else 0 for i in master['WL']]\n",
    "master['WL'] = result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify which features have missing values\n",
    "master.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Player Headshots (except G-League) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_headshots = grab_player_headshots(master[master['LEAGUE'] == 'NBA'], 'NBA')\n",
    "nba_headshots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnba_headshots = grab_player_headshots(master[master['LEAGUE'] == 'WNBA'], 'WNBA')\n",
    "wnba_headshots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Count of NBA Players w/ valid headshots:\", len(nba_headshots[nba_headshots['IMAGE'] != 'url_to_default_image']), \"out of\", len(nba_headshots))\n",
    "print(\"Count of WNBA Players w/ valid headshots:\", len(wnba_headshots[wnba_headshots['IMAGE'] != 'url_to_default_image']), \"out of\", len(wnba_headshots))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to revisit these two datasets later when we begin visualizing clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization: normalizing features ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I go further, I want to check if my data is normally distributed before I standardize the features by plotting each league's player statistics as a histogram and plotting correlation matrix.\n",
    "\n",
    "Using Scikit-learn, I'm either going to use:\n",
    "- `StandardScaler` (beneficial when data is approximately normally distributed or when using algorithms sensitive to the distribution of data)\n",
    "- `MinMaxScaler` (beneficial when you need data within a specific range or when using algorithms that do not assume any particular distribution of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numeric and descriptive columns\n",
    "numeric_columns = [\"MIN\", \"PTS\", \"FGM\", \"FGA\",\n",
    "                   \"FG3M\", \"FG3A\", \"FTM\", \"FTA\", \n",
    "                   \"OREB\", \"DREB\", \"REB\", \"AST\", \n",
    "                   \"STL\", \"BLK\", \"TOV\", \"PF\"]\n",
    "\n",
    "# Convert columns to float type\n",
    "for col in numeric_columns:\n",
    "    master[col] = master[col].astype(float)\n",
    "\n",
    "\n",
    "descriptive_columns = master.select_dtypes(exclude=['float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteratively plot each league's histogram statistics and correlation matrix. \n",
    "\n",
    "for league in master['LEAGUE'].unique():\n",
    "    df = master[master['LEAGUE'] == league]\n",
    "    historical_player_avg = df[['PLAYER_NAME'] + list(numeric_columns)].groupby('PLAYER_NAME').mean()\n",
    "    historical_player_avg.reset_index(inplace=True)\n",
    "\n",
    "    # Compute correlation between all columns except the first one\n",
    "    correlation_matrix = historical_player_avg.iloc[:, 1:].corr()\n",
    "    \n",
    "    # Create a figure with 2 subplots\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))\n",
    "\n",
    "    # Plot the correlation matrix on the first subplot\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='BuGn', ax=axes[0])\n",
    "    axes[0].set_title(f\"Correlation matrix of Player Metrics - {league}\", weight='bold')\n",
    "\n",
    "    # Plot the histograms on the second subplot\n",
    "    for col in numeric_columns:\n",
    "        historical_player_avg[col].hist(ax=axes[1], bins=20, alpha=0.5, label=col)\n",
    "    axes[1].set_title(f\"Histograms of Player Metrics - {league}\", weight='bold')\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying MinMaxScaler to numeric features ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that most of the features in the data are not normally distributed (excluding Personal Fouls and Minutes). Many of them show a skewed distribution, often right-skewed (positive skewness). Since most of the data is skewed right, a MinMaxScaler would be more appropriate to use since it's not normally distributed and it will scale all features to a specific range [0, 1]. \n",
    "\n",
    "In order to do this, let's apply the MinMaxScaler to numeric features only. Let's create a copy of `master` to differentiate between raw and normalized statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Create a copy of df to separate raw and normalized statistics\n",
    "master_std = master.copy()\n",
    "\n",
    "# Apply the scaler to the numeric columns\n",
    "master_std[numeric_columns] = scaler.fit_transform(master_std[numeric_columns])\n",
    "\n",
    "# Add \"_STD\" to the column names\n",
    "master_std.rename(columns={col: f\"{col}_STD\" for col in numeric_columns}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if lengths match\n",
    "assert len(master_std) == len(master), \"Length mismatch between normalized data and original data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to split our main table into 3 dataframes (NBA, WNBA, G-League) of player averages spanned across their lifetime by grouping by `PLAYER_NAME` (similar to what we did before when analyzing player distributions) and attach our player headshots to each dataset. We do this because we want to implement the clustering algorithm where one value represents one player, and not one performance of their game (side note: that would also be interesting to see how a player's performance varies). **Our goal is to see whose standardized performances are most similar.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns_std = [str(col + \"_STD\") for col in numeric_columns]\n",
    "\n",
    "cluster_df = pd.concat([master_std, master[numeric_columns]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = []\n",
    "\n",
    "for league in cluster_df['LEAGUE'].unique():\n",
    "    # filter for each league\n",
    "    df = cluster_df[cluster_df['LEAGUE'] == league]\n",
    "\n",
    "    # Ensure PLAYER_NAME is included in the DataFrame before grouping\n",
    "    df = df[['PLAYER_NAME'] + list(numeric_columns_std) + list(numeric_columns)]\n",
    "\n",
    "    historical_player_avg = df.groupby('PLAYER_NAME').mean()\n",
    "    historical_player_avg.reset_index(inplace=True)\n",
    "    list_of_dfs.append(historical_player_avg)\n",
    "\n",
    "nba_cluster = list_of_dfs[0]\n",
    "gleague_cluster = list_of_dfs[1]\n",
    "wnba_cluster = list_of_dfs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the dataframes on PLAYER_NAME\n",
    "nba_cluster = pd.merge(nba_cluster, nba_headshots, on='PLAYER_NAME', how='left')\n",
    "nba_cluster = nba_cluster[nba_cluster['IMAGE'] != 'url_to_default_image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the dataframes on PLAYER_NAME\n",
    "wnba_cluster = pd.merge(wnba_cluster, wnba_headshots, on='PLAYER_NAME', how='left')\n",
    "wnba_cluster = wnba_cluster[wnba_cluster['IMAGE'] != 'url_to_default_image']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A note about Elbow Method and Silhouette Score:*\n",
    "- I wanted to try these methods to find out the optimal k for clustering. However, both methods show that 2 is the optimal k. I believe this might be the case since each position is really a variation between guards and forwards. So I'm going to use k = 5 since we have 5 players on the court at all times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization: Clustering begins ##\n",
    "Now we're going to visualize our players' standardized career stats against each other and see whose games are most similar. \n",
    "\n",
    "### Method ###\n",
    "- Implement T-SNE to visualize data into a 2D plot so we can quickly see clusters of players who have similar playing styles or statistical profiles. For example:\n",
    "  - Players who score a lot and have similar shooting percentages might end up grouped together. Whereas players with different stats are placed far apart. So, a player who focuses on defense with many blocks and steals will be far from a player who scores a lot but doesn't have many defensive stats.\n",
    "- We're going to use our functions we defined earlier in the notebook.\n",
    "   - `apply_tsne` : used to apply T-SNE to our data and append/encode player headshots\n",
    "   - `plotly_clusters` : used to visualize clustering with plotly library \n",
    "\n",
    "Note: \n",
    "- [According to `py_ball` documentation](https://github.com/basketballrelativity/py_ball/wiki/Image), G League Player headshots aren't available using the `image` function. This is only available for NBA and WNBA players. So I'm going to visualize the G-League data along with NBA as dots rather than headshots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NBA ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_final = apply_tsne(nba_cluster, num_of_clusters = 5, numeric_columns=numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_clusters(nba_final, \"NBA\", season_start = season_start, season_end=season_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WNBA ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnba_final = apply_tsne(wnba_cluster, num_of_clusters = 5, numeric_columns=numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_clusters(wnba_final, \"WNBA\", season_start=season_start, season_end=season_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G-League ###\n",
    "*note: cluster plot won't show player headshots*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gleague_final = apply_tsne(gleague_cluster, num_of_clusters = 5, numeric_columns=numeric_columns, gleague = 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_clusters(gleague_final, \"G-LEAGUE\", season_start=season_start, season_end=season_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSIS coming soon ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
